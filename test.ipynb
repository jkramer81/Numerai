{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from hpo import gbm_hpo, nn_hpo, ae_hpo\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numerapi\n",
    "\n",
    "def credentials():\n",
    "    dotenv_path = 'num_config.env'\n",
    "    load_dotenv(dotenv_path=dotenv_path)\n",
    "    pub_id = os.getenv('PUBLIC_ID')\n",
    "    priv_key = os.getenv('PRIVATE_KEY')\n",
    "    latest_round = os.getenv('LATEST_ROUND')\n",
    "    #pub_id = \"C4Q5XUHAH3MSMAHHHRHSQWHG2SUW5Q54\"\n",
    "    #priv_key = \"QSBJY72HUPPDJBP3UF7JPFHRK4CV3ITWOEWQNWXD44RUTVORXQCB5BYIQK7I4CMD\"\n",
    "    #latest_round = 156\n",
    "    return {'PUBLIC_ID': pub_id, 'PRIVATE_KEY': priv_key, 'LATEST_ROUND': latest_round}\n",
    "\n",
    "\n",
    "def download_data(api: numerapi.NumerAPI, keys):\n",
    "    if int(keys['LATEST_ROUND']) == api.get_current_round():\n",
    "        return int(keys['LATEST_ROUND'])\n",
    "    else:\n",
    "        LATEST_ROUND = api.get_current_round()\n",
    "        api.download_current_dataset('./data')\n",
    "        return LATEST_ROUND\n",
    "\n",
    "\n",
    "def update_env_file(env_vars):\n",
    "    with open('num_config.env', 'w') as f:\n",
    "        f.write(f'LATEST_ROUND={env_vars[\"LATEST_ROUND\"]}\\n')\n",
    "        f.write(f'PUBLIC_ID={env_vars[\"PUBLIC_ID\"]}\\n')\n",
    "        f.write(f'PRIVATE_KEY={env_vars[\"PRIVATE_KEY\"]}\\n')\n",
    "\n",
    "def create_preds():\n",
    "    pass\n",
    "\n",
    "keys = credentials()\n",
    "numapi = numerapi.NumerAPI(\n",
    "        verbosity='INFO', public_id=keys['PUBLIC_ID'], secret_key=keys['PRIVATE_KEY'])\n",
    "keys['LATEST_ROUND'] = download_data(numapi, keys)\n",
    "update_env_file(keys)\n",
    "#gbm_hpo.main()\n",
    "#ae_hpo.main()\n",
    "#print(\"nn_hpo...\")\n",
    "# nn_hpo.main(train_ae=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "from data_loading import utils, purged_group_time_series\n",
    "from data_loading.utils import load_data, preprocess_data, FinData, weighted_mean, seed_everything, calc_data_mean, \\\n",
    "    create_dataloaders\n",
    "from models import resnet, lightning_nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import joblib\n",
    "from models.SupervisedAutoEncoder import SupAE, create_hidden_rep\n",
    "import os\n",
    "from data_loading import purged_group_time_series as pgs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alid_0's l2: 0.0497545\n",
      "[189]\tvalid_0's l2: 0.0497545\n",
      "[190]\tvalid_0's l2: 0.0497545\n",
      "[191]\tvalid_0's l2: 0.0497542\n",
      "[192]\tvalid_0's l2: 0.0497541\n",
      "[193]\tvalid_0's l2: 0.049754\n",
      "[194]\tvalid_0's l2: 0.049754\n",
      "[195]\tvalid_0's l2: 0.049754\n",
      "[196]\tvalid_0's l2: 0.0497538\n",
      "[197]\tvalid_0's l2: 0.0497537\n",
      "[198]\tvalid_0's l2: 0.0497534\n",
      "[199]\tvalid_0's l2: 0.0497533\n",
      "[200]\tvalid_0's l2: 0.0497533\n",
      "[201]\tvalid_0's l2: 0.049753\n",
      "[202]\tvalid_0's l2: 0.0497526\n",
      "[203]\tvalid_0's l2: 0.0497527\n",
      "[204]\tvalid_0's l2: 0.0497523\n",
      "[205]\tvalid_0's l2: 0.0497522\n",
      "[206]\tvalid_0's l2: 0.0497521\n",
      "[207]\tvalid_0's l2: 0.0497526\n",
      "[208]\tvalid_0's l2: 0.0497523\n",
      "[209]\tvalid_0's l2: 0.0497525\n",
      "[210]\tvalid_0's l2: 0.0497524\n",
      "[211]\tvalid_0's l2: 0.0497522\n",
      "[212]\tvalid_0's l2: 0.0497518\n",
      "[213]\tvalid_0's l2: 0.0497516\n",
      "[214]\tvalid_0's l2: 0.0497519\n",
      "[215]\tvalid_0's l2: 0.0497518\n",
      "[216]\tvalid_0's l2: 0.0497518\n",
      "[217]\tvalid_0's l2: 0.0497519\n",
      "[218]\tvalid_0's l2: 0.0497518\n",
      "[219]\tvalid_0's l2: 0.0497518\n",
      "[220]\tvalid_0's l2: 0.0497513\n",
      "[221]\tvalid_0's l2: 0.0497517\n",
      "[222]\tvalid_0's l2: 0.0497517\n",
      "[223]\tvalid_0's l2: 0.0497518\n",
      "[224]\tvalid_0's l2: 0.0497518\n",
      "[225]\tvalid_0's l2: 0.0497518\n",
      "[226]\tvalid_0's l2: 0.049752\n",
      "[227]\tvalid_0's l2: 0.0497527\n",
      "[228]\tvalid_0's l2: 0.0497527\n",
      "[229]\tvalid_0's l2: 0.0497524\n",
      "[230]\tvalid_0's l2: 0.0497516\n",
      "[231]\tvalid_0's l2: 0.0497519\n",
      "[232]\tvalid_0's l2: 0.0497521\n",
      "[233]\tvalid_0's l2: 0.0497525\n",
      "[234]\tvalid_0's l2: 0.0497526\n",
      "[235]\tvalid_0's l2: 0.0497524\n",
      "[236]\tvalid_0's l2: 0.0497521\n",
      "[237]\tvalid_0's l2: 0.0497525\n",
      "[238]\tvalid_0's l2: 0.049752\n",
      "[239]\tvalid_0's l2: 0.0497517\n",
      "[240]\tvalid_0's l2: 0.0497516\n",
      "[241]\tvalid_0's l2: 0.0497517\n",
      "[242]\tvalid_0's l2: 0.0497519\n",
      "[243]\tvalid_0's l2: 0.049752\n",
      "[244]\tvalid_0's l2: 0.0497523\n",
      "[245]\tvalid_0's l2: 0.0497521\n",
      "[246]\tvalid_0's l2: 0.0497521\n",
      "[247]\tvalid_0's l2: 0.0497522\n",
      "[248]\tvalid_0's l2: 0.0497526\n",
      "[249]\tvalid_0's l2: 0.0497529\n",
      "[250]\tvalid_0's l2: 0.0497533\n",
      "[251]\tvalid_0's l2: 0.0497526\n",
      "[252]\tvalid_0's l2: 0.0497528\n",
      "[253]\tvalid_0's l2: 0.0497526\n",
      "[254]\tvalid_0's l2: 0.0497526\n",
      "[255]\tvalid_0's l2: 0.0497521\n",
      "[256]\tvalid_0's l2: 0.0497526\n",
      "[257]\tvalid_0's l2: 0.0497528\n",
      "[258]\tvalid_0's l2: 0.0497523\n",
      "[259]\tvalid_0's l2: 0.0497514\n",
      "[260]\tvalid_0's l2: 0.0497513\n",
      "[261]\tvalid_0's l2: 0.0497516\n",
      "[262]\tvalid_0's l2: 0.0497513\n",
      "[263]\tvalid_0's l2: 0.0497512\n",
      "[264]\tvalid_0's l2: 0.0497516\n",
      "[265]\tvalid_0's l2: 0.0497513\n",
      "[266]\tvalid_0's l2: 0.0497507\n",
      "[267]\tvalid_0's l2: 0.0497503\n",
      "[268]\tvalid_0's l2: 0.0497499\n",
      "[269]\tvalid_0's l2: 0.0497497\n",
      "[270]\tvalid_0's l2: 0.0497493\n",
      "[271]\tvalid_0's l2: 0.0497492\n",
      "[272]\tvalid_0's l2: 0.0497488\n",
      "[273]\tvalid_0's l2: 0.0497483\n",
      "[274]\tvalid_0's l2: 0.049748\n",
      "[275]\tvalid_0's l2: 0.0497485\n",
      "[276]\tvalid_0's l2: 0.0497488\n",
      "[277]\tvalid_0's l2: 0.0497485\n",
      "[278]\tvalid_0's l2: 0.0497484\n",
      "[279]\tvalid_0's l2: 0.0497487\n",
      "[280]\tvalid_0's l2: 0.0497486\n",
      "[281]\tvalid_0's l2: 0.0497483\n",
      "[282]\tvalid_0's l2: 0.0497482\n",
      "[283]\tvalid_0's l2: 0.0497479\n",
      "[284]\tvalid_0's l2: 0.0497481\n",
      "[285]\tvalid_0's l2: 0.0497475\n",
      "[286]\tvalid_0's l2: 0.0497474\n",
      "[287]\tvalid_0's l2: 0.0497471\n",
      "[288]\tvalid_0's l2: 0.0497462\n",
      "[289]\tvalid_0's l2: 0.0497463\n",
      "[290]\tvalid_0's l2: 0.0497459\n",
      "[291]\tvalid_0's l2: 0.0497464\n",
      "[292]\tvalid_0's l2: 0.0497462\n",
      "[293]\tvalid_0's l2: 0.0497462\n",
      "[294]\tvalid_0's l2: 0.049746\n",
      "[295]\tvalid_0's l2: 0.0497456\n",
      "[296]\tvalid_0's l2: 0.0497451\n",
      "[297]\tvalid_0's l2: 0.0497455\n",
      "[298]\tvalid_0's l2: 0.0497456\n",
      "[299]\tvalid_0's l2: 0.0497453\n",
      "[300]\tvalid_0's l2: 0.0497455\n",
      "[301]\tvalid_0's l2: 0.0497458\n",
      "[302]\tvalid_0's l2: 0.0497461\n",
      "[303]\tvalid_0's l2: 0.0497463\n",
      "[304]\tvalid_0's l2: 0.0497458\n",
      "[305]\tvalid_0's l2: 0.049746\n",
      "[306]\tvalid_0's l2: 0.049746\n",
      "[307]\tvalid_0's l2: 0.0497465\n",
      "[308]\tvalid_0's l2: 0.0497465\n",
      "[309]\tvalid_0's l2: 0.0497461\n",
      "[310]\tvalid_0's l2: 0.0497461\n",
      "[311]\tvalid_0's l2: 0.0497455\n",
      "[312]\tvalid_0's l2: 0.0497455\n",
      "[313]\tvalid_0's l2: 0.0497452\n",
      "[314]\tvalid_0's l2: 0.049745\n",
      "[315]\tvalid_0's l2: 0.0497446\n",
      "[316]\tvalid_0's l2: 0.0497444\n",
      "[317]\tvalid_0's l2: 0.0497443\n",
      "[318]\tvalid_0's l2: 0.0497444\n",
      "[319]\tvalid_0's l2: 0.0497441\n",
      "[320]\tvalid_0's l2: 0.049744\n",
      "[321]\tvalid_0's l2: 0.0497437\n",
      "[322]\tvalid_0's l2: 0.0497439\n",
      "[323]\tvalid_0's l2: 0.0497436\n",
      "[324]\tvalid_0's l2: 0.0497439\n",
      "[325]\tvalid_0's l2: 0.0497439\n",
      "[326]\tvalid_0's l2: 0.0497441\n",
      "[327]\tvalid_0's l2: 0.0497443\n",
      "[328]\tvalid_0's l2: 0.0497443\n",
      "[329]\tvalid_0's l2: 0.0497441\n",
      "[330]\tvalid_0's l2: 0.0497438\n",
      "[331]\tvalid_0's l2: 0.0497444\n",
      "[332]\tvalid_0's l2: 0.0497447\n",
      "[333]\tvalid_0's l2: 0.0497447\n",
      "[334]\tvalid_0's l2: 0.0497453\n",
      "[335]\tvalid_0's l2: 0.0497452\n",
      "[336]\tvalid_0's l2: 0.0497456\n",
      "[337]\tvalid_0's l2: 0.049745\n",
      "[338]\tvalid_0's l2: 0.0497457\n",
      "[339]\tvalid_0's l2: 0.0497463\n",
      "[340]\tvalid_0's l2: 0.0497461\n",
      "[341]\tvalid_0's l2: 0.0497458\n",
      "[342]\tvalid_0's l2: 0.0497457\n",
      "[343]\tvalid_0's l2: 0.0497454\n",
      "[344]\tvalid_0's l2: 0.0497453\n",
      "[345]\tvalid_0's l2: 0.0497449\n",
      "[346]\tvalid_0's l2: 0.0497446\n",
      "[347]\tvalid_0's l2: 0.0497449\n",
      "[348]\tvalid_0's l2: 0.0497449\n",
      "[349]\tvalid_0's l2: 0.0497452\n",
      "[350]\tvalid_0's l2: 0.0497457\n",
      "[351]\tvalid_0's l2: 0.0497452\n",
      "[352]\tvalid_0's l2: 0.0497452\n",
      "[353]\tvalid_0's l2: 0.0497456\n",
      "[354]\tvalid_0's l2: 0.0497456\n",
      "[355]\tvalid_0's l2: 0.0497452\n",
      "[356]\tvalid_0's l2: 0.0497443\n",
      "[357]\tvalid_0's l2: 0.0497443\n",
      "[358]\tvalid_0's l2: 0.049744\n",
      "[359]\tvalid_0's l2: 0.0497437\n",
      "[360]\tvalid_0's l2: 0.049744\n",
      "[361]\tvalid_0's l2: 0.0497436\n",
      "[362]\tvalid_0's l2: 0.0497431\n",
      "[363]\tvalid_0's l2: 0.0497428\n",
      "[364]\tvalid_0's l2: 0.0497428\n",
      "[365]\tvalid_0's l2: 0.0497425\n",
      "[366]\tvalid_0's l2: 0.0497423\n",
      "[367]\tvalid_0's l2: 0.0497416\n",
      "[368]\tvalid_0's l2: 0.0497419\n",
      "[369]\tvalid_0's l2: 0.0497416\n",
      "[370]\tvalid_0's l2: 0.0497415\n",
      "[371]\tvalid_0's l2: 0.0497411\n",
      "[372]\tvalid_0's l2: 0.0497408\n",
      "[373]\tvalid_0's l2: 0.0497406\n",
      "[374]\tvalid_0's l2: 0.0497403\n",
      "[375]\tvalid_0's l2: 0.0497404\n",
      "[376]\tvalid_0's l2: 0.0497405\n",
      "[377]\tvalid_0's l2: 0.0497406\n",
      "[378]\tvalid_0's l2: 0.0497406\n",
      "[379]\tvalid_0's l2: 0.0497406\n",
      "[380]\tvalid_0's l2: 0.0497404\n",
      "[381]\tvalid_0's l2: 0.0497406\n",
      "[382]\tvalid_0's l2: 0.0497404\n",
      "[383]\tvalid_0's l2: 0.0497402\n",
      "[384]\tvalid_0's l2: 0.0497399\n",
      "[385]\tvalid_0's l2: 0.0497399\n",
      "[386]\tvalid_0's l2: 0.04974\n",
      "[387]\tvalid_0's l2: 0.0497402\n",
      "[388]\tvalid_0's l2: 0.0497406\n",
      "[389]\tvalid_0's l2: 0.049741\n",
      "[390]\tvalid_0's l2: 0.049741\n",
      "[391]\tvalid_0's l2: 0.0497409\n",
      "[392]\tvalid_0's l2: 0.0497409\n",
      "[393]\tvalid_0's l2: 0.0497408\n",
      "[394]\tvalid_0's l2: 0.0497411\n",
      "[395]\tvalid_0's l2: 0.0497411\n",
      "[396]\tvalid_0's l2: 0.0497414\n",
      "[397]\tvalid_0's l2: 0.0497413\n",
      "[398]\tvalid_0's l2: 0.0497414\n",
      "[399]\tvalid_0's l2: 0.0497412\n",
      "[400]\tvalid_0's l2: 0.0497412\n",
      "[401]\tvalid_0's l2: 0.0497412\n",
      "[402]\tvalid_0's l2: 0.0497413\n",
      "[403]\tvalid_0's l2: 0.0497415\n",
      "[404]\tvalid_0's l2: 0.0497416\n",
      "[405]\tvalid_0's l2: 0.0497414\n",
      "[406]\tvalid_0's l2: 0.0497411\n",
      "[407]\tvalid_0's l2: 0.049741\n",
      "[408]\tvalid_0's l2: 0.0497414\n",
      "[409]\tvalid_0's l2: 0.0497417\n",
      "[410]\tvalid_0's l2: 0.0497417\n",
      "[411]\tvalid_0's l2: 0.0497418\n",
      "[412]\tvalid_0's l2: 0.0497419\n",
      "[413]\tvalid_0's l2: 0.0497418\n",
      "[414]\tvalid_0's l2: 0.0497417\n",
      "[415]\tvalid_0's l2: 0.0497413\n",
      "[416]\tvalid_0's l2: 0.0497412\n",
      "[417]\tvalid_0's l2: 0.0497412\n",
      "[418]\tvalid_0's l2: 0.0497408\n",
      "[419]\tvalid_0's l2: 0.0497407\n",
      "[420]\tvalid_0's l2: 0.0497414\n",
      "[421]\tvalid_0's l2: 0.0497414\n",
      "[422]\tvalid_0's l2: 0.0497408\n",
      "[423]\tvalid_0's l2: 0.0497409\n",
      "[424]\tvalid_0's l2: 0.0497411\n",
      "[425]\tvalid_0's l2: 0.0497409\n",
      "[426]\tvalid_0's l2: 0.0497406\n",
      "[427]\tvalid_0's l2: 0.0497411\n",
      "[428]\tvalid_0's l2: 0.0497414\n",
      "[429]\tvalid_0's l2: 0.0497408\n",
      "[430]\tvalid_0's l2: 0.0497408\n",
      "[431]\tvalid_0's l2: 0.0497406\n",
      "[432]\tvalid_0's l2: 0.0497407\n",
      "[433]\tvalid_0's l2: 0.0497406\n",
      "[434]\tvalid_0's l2: 0.0497405\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's l2: 0.0497399\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1550\n",
      "[LightGBM] [Info] Number of data points in the train set: 364958, number of used features: 310\n",
      "[LightGBM] [Info] Start training from score 0.499989\n",
      "[1]\tvalid_0's l2: 0.0498567\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's l2: 0.0498557\n",
      "[3]\tvalid_0's l2: 0.0498548\n",
      "[4]\tvalid_0's l2: 0.049854\n",
      "[5]\tvalid_0's l2: 0.0498527\n",
      "[6]\tvalid_0's l2: 0.049852\n",
      "[7]\tvalid_0's l2: 0.0498515\n",
      "[8]\tvalid_0's l2: 0.0498504\n",
      "[9]\tvalid_0's l2: 0.0498498\n",
      "[10]\tvalid_0's l2: 0.049849\n",
      "[11]\tvalid_0's l2: 0.0498476\n",
      "[12]\tvalid_0's l2: 0.0498469\n",
      "[13]\tvalid_0's l2: 0.0498459\n",
      "[14]\tvalid_0's l2: 0.0498448\n",
      "[15]\tvalid_0's l2: 0.0498438\n",
      "[16]\tvalid_0's l2: 0.0498429\n",
      "[17]\tvalid_0's l2: 0.0498418\n",
      "[18]\tvalid_0's l2: 0.0498406\n",
      "[19]\tvalid_0's l2: 0.0498397\n",
      "[20]\tvalid_0's l2: 0.0498389\n",
      "[21]\tvalid_0's l2: 0.0498379\n",
      "[22]\tvalid_0's l2: 0.049837\n",
      "[23]\tvalid_0's l2: 0.0498361\n",
      "[24]\tvalid_0's l2: 0.0498348\n",
      "[25]\tvalid_0's l2: 0.0498337\n",
      "[26]\tvalid_0's l2: 0.0498329\n",
      "[27]\tvalid_0's l2: 0.0498325\n",
      "[28]\tvalid_0's l2: 0.0498316\n",
      "[29]\tvalid_0's l2: 0.049831\n",
      "[30]\tvalid_0's l2: 0.0498304\n",
      "[31]\tvalid_0's l2: 0.0498294\n",
      "[32]\tvalid_0's l2: 0.0498284\n",
      "[33]\tvalid_0's l2: 0.0498277\n",
      "[34]\tvalid_0's l2: 0.0498272\n",
      "[35]\tvalid_0's l2: 0.0498265\n",
      "[36]\tvalid_0's l2: 0.0498257\n",
      "[37]\tvalid_0's l2: 0.0498248\n",
      "[38]\tvalid_0's l2: 0.0498239\n",
      "[39]\tvalid_0's l2: 0.0498236\n",
      "[40]\tvalid_0's l2: 0.0498227\n",
      "[41]\tvalid_0's l2: 0.0498221\n",
      "[42]\tvalid_0's l2: 0.0498218\n",
      "[43]\tvalid_0's l2: 0.0498213\n",
      "[44]\tvalid_0's l2: 0.0498206\n",
      "[45]\tvalid_0's l2: 0.0498204\n",
      "[46]\tvalid_0's l2: 0.0498198\n",
      "[47]\tvalid_0's l2: 0.0498185\n",
      "[48]\tvalid_0's l2: 0.0498177\n",
      "[49]\tvalid_0's l2: 0.0498174\n",
      "[50]\tvalid_0's l2: 0.0498173\n",
      "[51]\tvalid_0's l2: 0.0498166\n",
      "[52]\tvalid_0's l2: 0.049816\n",
      "[53]\tvalid_0's l2: 0.0498152\n",
      "[54]\tvalid_0's l2: 0.0498147\n",
      "[55]\tvalid_0's l2: 0.0498137\n",
      "[56]\tvalid_0's l2: 0.0498135\n",
      "[57]\tvalid_0's l2: 0.0498125\n",
      "[58]\tvalid_0's l2: 0.0498118\n",
      "[59]\tvalid_0's l2: 0.0498109\n",
      "[60]\tvalid_0's l2: 0.04981\n",
      "[61]\tvalid_0's l2: 0.049809\n",
      "[62]\tvalid_0's l2: 0.0498086\n",
      "[63]\tvalid_0's l2: 0.0498074\n",
      "[64]\tvalid_0's l2: 0.049807\n",
      "[65]\tvalid_0's l2: 0.0498068\n",
      "[66]\tvalid_0's l2: 0.049806\n",
      "[67]\tvalid_0's l2: 0.0498051\n",
      "[68]\tvalid_0's l2: 0.0498044\n",
      "[69]\tvalid_0's l2: 0.0498037\n",
      "[70]\tvalid_0's l2: 0.0498028\n",
      "[71]\tvalid_0's l2: 0.0498025\n",
      "[72]\tvalid_0's l2: 0.0498018\n",
      "[73]\tvalid_0's l2: 0.0498016\n",
      "[74]\tvalid_0's l2: 0.049801\n",
      "[75]\tvalid_0's l2: 0.0497999\n",
      "[76]\tvalid_0's l2: 0.0497997\n",
      "[77]\tvalid_0's l2: 0.049799\n",
      "[78]\tvalid_0's l2: 0.0497985\n",
      "[79]\tvalid_0's l2: 0.0497984\n",
      "[80]\tvalid_0's l2: 0.0497981\n",
      "[81]\tvalid_0's l2: 0.0497976\n",
      "[82]\tvalid_0's l2: 0.0497972\n",
      "[83]\tvalid_0's l2: 0.0497969\n",
      "[84]\tvalid_0's l2: 0.0497971\n",
      "[85]\tvalid_0's l2: 0.0497965\n",
      "[86]\tvalid_0's l2: 0.0497962\n",
      "[87]\tvalid_0's l2: 0.0497958\n",
      "[88]\tvalid_0's l2: 0.0497957\n",
      "[89]\tvalid_0's l2: 0.0497947\n",
      "[90]\tvalid_0's l2: 0.0497949\n",
      "[91]\tvalid_0's l2: 0.0497949\n",
      "[92]\tvalid_0's l2: 0.0497941\n",
      "[93]\tvalid_0's l2: 0.0497945\n",
      "[94]\tvalid_0's l2: 0.0497939\n",
      "[95]\tvalid_0's l2: 0.0497944\n",
      "[96]\tvalid_0's l2: 0.0497942\n",
      "[97]\tvalid_0's l2: 0.0497936\n",
      "[98]\tvalid_0's l2: 0.0497933\n",
      "[99]\tvalid_0's l2: 0.0497934\n",
      "[100]\tvalid_0's l2: 0.0497935\n",
      "[101]\tvalid_0's l2: 0.049793\n",
      "[102]\tvalid_0's l2: 0.0497929\n",
      "[103]\tvalid_0's l2: 0.0497918\n",
      "[104]\tvalid_0's l2: 0.0497914\n",
      "[105]\tvalid_0's l2: 0.0497911\n",
      "[106]\tvalid_0's l2: 0.0497905\n",
      "[107]\tvalid_0's l2: 0.049791\n",
      "[108]\tvalid_0's l2: 0.0497905\n",
      "[109]\tvalid_0's l2: 0.04979\n",
      "[110]\tvalid_0's l2: 0.0497898\n",
      "[111]\tvalid_0's l2: 0.0497894\n",
      "[112]\tvalid_0's l2: 0.0497889\n",
      "[113]\tvalid_0's l2: 0.0497887\n",
      "[114]\tvalid_0's l2: 0.0497884\n",
      "[115]\tvalid_0's l2: 0.0497878\n",
      "[116]\tvalid_0's l2: 0.0497876\n",
      "[117]\tvalid_0's l2: 0.0497874\n",
      "[118]\tvalid_0's l2: 0.0497871\n",
      "[119]\tvalid_0's l2: 0.0497874\n",
      "[120]\tvalid_0's l2: 0.0497873\n",
      "[121]\tvalid_0's l2: 0.049787\n",
      "[122]\tvalid_0's l2: 0.0497871\n",
      "[123]\tvalid_0's l2: 0.049787\n",
      "[124]\tvalid_0's l2: 0.049787\n",
      "[125]\tvalid_0's l2: 0.0497868\n",
      "[126]\tvalid_0's l2: 0.0497872\n",
      "[127]\tvalid_0's l2: 0.049787\n",
      "[128]\tvalid_0's l2: 0.0497872\n",
      "[129]\tvalid_0's l2: 0.0497872\n",
      "[130]\tvalid_0's l2: 0.0497869\n",
      "[131]\tvalid_0's l2: 0.0497867\n",
      "[132]\tvalid_0's l2: 0.0497863\n",
      "[133]\tvalid_0's l2: 0.0497862\n",
      "[134]\tvalid_0's l2: 0.0497861\n",
      "[135]\tvalid_0's l2: 0.049786\n",
      "[136]\tvalid_0's l2: 0.0497855\n",
      "[137]\tvalid_0's l2: 0.0497854\n",
      "[138]\tvalid_0's l2: 0.0497852\n",
      "[139]\tvalid_0's l2: 0.0497846\n",
      "[140]\tvalid_0's l2: 0.0497843\n",
      "[141]\tvalid_0's l2: 0.0497842\n",
      "[142]\tvalid_0's l2: 0.0497842\n",
      "[143]\tvalid_0's l2: 0.0497843\n",
      "[144]\tvalid_0's l2: 0.0497838\n",
      "[145]\tvalid_0's l2: 0.0497836\n",
      "[146]\tvalid_0's l2: 0.0497831\n",
      "[147]\tvalid_0's l2: 0.0497831\n",
      "[148]\tvalid_0's l2: 0.0497829\n",
      "[149]\tvalid_0's l2: 0.0497824\n",
      "[150]\tvalid_0's l2: 0.049782\n",
      "[151]\tvalid_0's l2: 0.0497821\n",
      "[152]\tvalid_0's l2: 0.0497824\n",
      "[153]\tvalid_0's l2: 0.049782\n",
      "[154]\tvalid_0's l2: 0.0497815\n",
      "[155]\tvalid_0's l2: 0.0497812\n",
      "[156]\tvalid_0's l2: 0.0497812\n",
      "[157]\tvalid_0's l2: 0.0497811\n",
      "[158]\tvalid_0's l2: 0.0497812\n",
      "[159]\tvalid_0's l2: 0.0497806\n",
      "[160]\tvalid_0's l2: 0.0497806\n",
      "[161]\tvalid_0's l2: 0.04978\n",
      "[162]\tvalid_0's l2: 0.0497794\n",
      "[163]\tvalid_0's l2: 0.0497788\n",
      "[164]\tvalid_0's l2: 0.049779\n",
      "[165]\tvalid_0's l2: 0.0497796\n",
      "[166]\tvalid_0's l2: 0.0497797\n",
      "[167]\tvalid_0's l2: 0.0497798\n",
      "[168]\tvalid_0's l2: 0.0497796\n",
      "[169]\tvalid_0's l2: 0.0497798\n",
      "[170]\tvalid_0's l2: 0.0497795\n",
      "[171]\tvalid_0's l2: 0.0497797\n",
      "[172]\tvalid_0's l2: 0.0497795\n",
      "[173]\tvalid_0's l2: 0.0497791\n",
      "[174]\tvalid_0's l2: 0.0497789\n",
      "[175]\tvalid_0's l2: 0.0497792\n",
      "[176]\tvalid_0's l2: 0.0497787\n",
      "[177]\tvalid_0's l2: 0.0497785\n",
      "[178]\tvalid_0's l2: 0.0497787\n",
      "[179]\tvalid_0's l2: 0.0497789\n",
      "[180]\tvalid_0's l2: 0.0497787\n",
      "[181]\tvalid_0's l2: 0.0497784\n",
      "[182]\tvalid_0's l2: 0.0497788\n",
      "[183]\tvalid_0's l2: 0.0497786\n",
      "[184]\tvalid_0's l2: 0.0497785\n",
      "[185]\tvalid_0's l2: 0.0497786\n",
      "[186]\tvalid_0's l2: 0.0497784\n",
      "[187]\tvalid_0's l2: 0.0497782\n",
      "[188]\tvalid_0's l2: 0.0497781\n",
      "[189]\tvalid_0's l2: 0.0497779\n",
      "[190]\tvalid_0's l2: 0.0497778\n",
      "[191]\tvalid_0's l2: 0.0497778\n",
      "[192]\tvalid_0's l2: 0.0497775\n",
      "[193]\tvalid_0's l2: 0.0497774\n",
      "[194]\tvalid_0's l2: 0.0497774\n",
      "[195]\tvalid_0's l2: 0.0497778\n",
      "[196]\tvalid_0's l2: 0.0497776\n",
      "[197]\tvalid_0's l2: 0.0497775\n",
      "[198]\tvalid_0's l2: 0.0497768\n",
      "[199]\tvalid_0's l2: 0.0497769\n",
      "[200]\tvalid_0's l2: 0.0497766\n",
      "[201]\tvalid_0's l2: 0.0497761\n",
      "[202]\tvalid_0's l2: 0.0497763\n",
      "[203]\tvalid_0's l2: 0.0497762\n",
      "[204]\tvalid_0's l2: 0.0497764\n",
      "[205]\tvalid_0's l2: 0.049776\n",
      "[206]\tvalid_0's l2: 0.049776\n",
      "[207]\tvalid_0's l2: 0.0497761\n",
      "[208]\tvalid_0's l2: 0.0497764\n",
      "[209]\tvalid_0's l2: 0.0497763\n",
      "[210]\tvalid_0's l2: 0.0497762\n",
      "[211]\tvalid_0's l2: 0.0497763\n",
      "[212]\tvalid_0's l2: 0.0497761\n",
      "[213]\tvalid_0's l2: 0.0497755\n",
      "[214]\tvalid_0's l2: 0.0497756\n",
      "[215]\tvalid_0's l2: 0.0497758\n",
      "[216]\tvalid_0's l2: 0.049775\n",
      "[217]\tvalid_0's l2: 0.0497751\n",
      "[218]\tvalid_0's l2: 0.0497749\n",
      "[219]\tvalid_0's l2: 0.0497751\n",
      "[220]\tvalid_0's l2: 0.0497753\n",
      "[221]\tvalid_0's l2: 0.0497753\n",
      "[222]\tvalid_0's l2: 0.049775\n",
      "[223]\tvalid_0's l2: 0.0497751\n",
      "[224]\tvalid_0's l2: 0.0497754\n",
      "[225]\tvalid_0's l2: 0.0497759\n",
      "[226]\tvalid_0's l2: 0.0497759\n",
      "[227]\tvalid_0's l2: 0.0497755\n",
      "[228]\tvalid_0's l2: 0.0497754\n",
      "[229]\tvalid_0's l2: 0.0497755\n",
      "[230]\tvalid_0's l2: 0.0497756\n",
      "[231]\tvalid_0's l2: 0.0497758\n",
      "[232]\tvalid_0's l2: 0.0497754\n",
      "[233]\tvalid_0's l2: 0.0497752\n",
      "[234]\tvalid_0's l2: 0.0497751\n",
      "[235]\tvalid_0's l2: 0.0497752\n",
      "[236]\tvalid_0's l2: 0.0497752\n",
      "[237]\tvalid_0's l2: 0.049775\n",
      "[238]\tvalid_0's l2: 0.0497745\n",
      "[239]\tvalid_0's l2: 0.0497745\n",
      "[240]\tvalid_0's l2: 0.0497745\n",
      "[241]\tvalid_0's l2: 0.049774\n",
      "[242]\tvalid_0's l2: 0.0497743\n",
      "[243]\tvalid_0's l2: 0.0497742\n",
      "[244]\tvalid_0's l2: 0.0497745\n",
      "[245]\tvalid_0's l2: 0.0497741\n",
      "[246]\tvalid_0's l2: 0.0497743\n",
      "[247]\tvalid_0's l2: 0.0497745\n",
      "[248]\tvalid_0's l2: 0.0497742\n",
      "[249]\tvalid_0's l2: 0.0497742\n",
      "[250]\tvalid_0's l2: 0.0497745\n",
      "[251]\tvalid_0's l2: 0.0497742\n",
      "[252]\tvalid_0's l2: 0.0497738\n",
      "[253]\tvalid_0's l2: 0.0497736\n",
      "[254]\tvalid_0's l2: 0.0497736\n",
      "[255]\tvalid_0's l2: 0.0497731\n",
      "[256]\tvalid_0's l2: 0.0497723\n",
      "[257]\tvalid_0's l2: 0.049772\n",
      "[258]\tvalid_0's l2: 0.049772\n",
      "[259]\tvalid_0's l2: 0.0497721\n",
      "[260]\tvalid_0's l2: 0.0497719\n",
      "[261]\tvalid_0's l2: 0.049772\n",
      "[262]\tvalid_0's l2: 0.0497719\n",
      "[263]\tvalid_0's l2: 0.0497715\n",
      "[264]\tvalid_0's l2: 0.049772\n",
      "[265]\tvalid_0's l2: 0.0497719\n",
      "[266]\tvalid_0's l2: 0.0497718\n",
      "[267]\tvalid_0's l2: 0.0497716\n",
      "[268]\tvalid_0's l2: 0.049771\n",
      "[269]\tvalid_0's l2: 0.0497708\n",
      "[270]\tvalid_0's l2: 0.0497709\n",
      "[271]\tvalid_0's l2: 0.0497712\n",
      "[272]\tvalid_0's l2: 0.0497714\n",
      "[273]\tvalid_0's l2: 0.0497713\n",
      "[274]\tvalid_0's l2: 0.049771\n",
      "[275]\tvalid_0's l2: 0.0497712\n",
      "[276]\tvalid_0's l2: 0.0497713\n",
      "[277]\tvalid_0's l2: 0.0497719\n",
      "[278]\tvalid_0's l2: 0.0497716\n",
      "[279]\tvalid_0's l2: 0.0497718\n",
      "[280]\tvalid_0's l2: 0.0497714\n",
      "[281]\tvalid_0's l2: 0.0497714\n",
      "[282]\tvalid_0's l2: 0.0497707\n",
      "[283]\tvalid_0's l2: 0.0497703\n",
      "[284]\tvalid_0's l2: 0.04977\n",
      "[285]\tvalid_0's l2: 0.0497698\n",
      "[286]\tvalid_0's l2: 0.0497701\n",
      "[287]\tvalid_0's l2: 0.0497705\n",
      "[288]\tvalid_0's l2: 0.0497702\n",
      "[289]\tvalid_0's l2: 0.0497699\n",
      "[290]\tvalid_0's l2: 0.04977\n",
      "[291]\tvalid_0's l2: 0.04977\n",
      "[292]\tvalid_0's l2: 0.0497698\n",
      "[293]\tvalid_0's l2: 0.0497696\n",
      "[294]\tvalid_0's l2: 0.0497693\n",
      "[295]\tvalid_0's l2: 0.0497691\n",
      "[296]\tvalid_0's l2: 0.0497688\n",
      "[297]\tvalid_0's l2: 0.0497686\n",
      "[298]\tvalid_0's l2: 0.0497682\n",
      "[299]\tvalid_0's l2: 0.0497681\n",
      "[300]\tvalid_0's l2: 0.0497679\n",
      "[301]\tvalid_0's l2: 0.0497677\n",
      "[302]\tvalid_0's l2: 0.0497673\n",
      "[303]\tvalid_0's l2: 0.0497673\n",
      "[304]\tvalid_0's l2: 0.0497676\n",
      "[305]\tvalid_0's l2: 0.0497676\n",
      "[306]\tvalid_0's l2: 0.0497678\n",
      "[307]\tvalid_0's l2: 0.0497674\n",
      "[308]\tvalid_0's l2: 0.049767\n",
      "[309]\tvalid_0's l2: 0.0497671\n",
      "[310]\tvalid_0's l2: 0.0497667\n",
      "[311]\tvalid_0's l2: 0.0497669\n",
      "[312]\tvalid_0's l2: 0.0497669\n",
      "[313]\tvalid_0's l2: 0.0497668\n",
      "[314]\tvalid_0's l2: 0.0497663\n",
      "[315]\tvalid_0's l2: 0.0497664\n",
      "[316]\tvalid_0's l2: 0.0497662\n",
      "[317]\tvalid_0's l2: 0.0497663\n",
      "[318]\tvalid_0's l2: 0.0497661\n",
      "[319]\tvalid_0's l2: 0.0497659\n",
      "[320]\tvalid_0's l2: 0.049766\n",
      "[321]\tvalid_0's l2: 0.0497659\n",
      "[322]\tvalid_0's l2: 0.0497658\n",
      "[323]\tvalid_0's l2: 0.0497663\n",
      "[324]\tvalid_0's l2: 0.0497657\n",
      "[325]\tvalid_0's l2: 0.0497658\n",
      "[326]\tvalid_0's l2: 0.0497658\n",
      "[327]\tvalid_0's l2: 0.0497658\n",
      "[328]\tvalid_0's l2: 0.0497662\n",
      "[329]\tvalid_0's l2: 0.0497663\n",
      "[330]\tvalid_0's l2: 0.0497663\n",
      "[331]\tvalid_0's l2: 0.0497664\n",
      "[332]\tvalid_0's l2: 0.0497663\n",
      "[333]\tvalid_0's l2: 0.0497662\n",
      "[334]\tvalid_0's l2: 0.0497663\n",
      "[335]\tvalid_0's l2: 0.0497663\n",
      "[336]\tvalid_0's l2: 0.0497663\n",
      "[337]\tvalid_0's l2: 0.0497663\n",
      "[338]\tvalid_0's l2: 0.0497661\n",
      "[339]\tvalid_0's l2: 0.0497662\n",
      "[340]\tvalid_0's l2: 0.0497663\n",
      "[341]\tvalid_0's l2: 0.0497664\n",
      "[342]\tvalid_0's l2: 0.0497666\n",
      "[343]\tvalid_0's l2: 0.049766\n",
      "[344]\tvalid_0's l2: 0.0497659\n",
      "[345]\tvalid_0's l2: 0.0497656\n",
      "[346]\tvalid_0's l2: 0.0497652\n",
      "[347]\tvalid_0's l2: 0.0497652\n",
      "[348]\tvalid_0's l2: 0.0497649\n",
      "[349]\tvalid_0's l2: 0.049765\n",
      "[350]\tvalid_0's l2: 0.0497649\n",
      "[351]\tvalid_0's l2: 0.0497648\n",
      "[352]\tvalid_0's l2: 0.0497645\n",
      "[353]\tvalid_0's l2: 0.0497646\n",
      "[354]\tvalid_0's l2: 0.0497644\n",
      "[355]\tvalid_0's l2: 0.0497645\n",
      "[356]\tvalid_0's l2: 0.0497641\n",
      "[357]\tvalid_0's l2: 0.0497642\n",
      "[358]\tvalid_0's l2: 0.0497647\n",
      "[359]\tvalid_0's l2: 0.0497646\n",
      "[360]\tvalid_0's l2: 0.0497654\n",
      "[361]\tvalid_0's l2: 0.0497655\n",
      "[362]\tvalid_0's l2: 0.0497656\n",
      "[363]\tvalid_0's l2: 0.0497655\n",
      "[364]\tvalid_0's l2: 0.0497653\n",
      "[365]\tvalid_0's l2: 0.0497655\n",
      "[366]\tvalid_0's l2: 0.0497654\n",
      "[367]\tvalid_0's l2: 0.0497657\n",
      "[368]\tvalid_0's l2: 0.049766\n",
      "[369]\tvalid_0's l2: 0.049766\n",
      "[370]\tvalid_0's l2: 0.0497658\n",
      "[371]\tvalid_0's l2: 0.0497659\n",
      "[372]\tvalid_0's l2: 0.049766\n",
      "[373]\tvalid_0's l2: 0.0497663\n",
      "[374]\tvalid_0's l2: 0.0497665\n",
      "[375]\tvalid_0's l2: 0.0497667\n",
      "[376]\tvalid_0's l2: 0.0497666\n",
      "[377]\tvalid_0's l2: 0.0497665\n",
      "[378]\tvalid_0's l2: 0.0497666\n",
      "[379]\tvalid_0's l2: 0.0497669\n",
      "[380]\tvalid_0's l2: 0.0497666\n",
      "[381]\tvalid_0's l2: 0.0497666\n",
      "[382]\tvalid_0's l2: 0.0497665\n",
      "[383]\tvalid_0's l2: 0.0497668\n",
      "[384]\tvalid_0's l2: 0.0497671\n",
      "[385]\tvalid_0's l2: 0.0497671\n",
      "[386]\tvalid_0's l2: 0.0497674\n",
      "[387]\tvalid_0's l2: 0.0497674\n",
      "[388]\tvalid_0's l2: 0.049767\n",
      "[389]\tvalid_0's l2: 0.0497673\n",
      "[390]\tvalid_0's l2: 0.0497668\n",
      "[391]\tvalid_0's l2: 0.0497672\n",
      "[392]\tvalid_0's l2: 0.0497672\n",
      "[393]\tvalid_0's l2: 0.049767\n",
      "[394]\tvalid_0's l2: 0.049767\n",
      "[395]\tvalid_0's l2: 0.0497673\n",
      "[396]\tvalid_0's l2: 0.0497672\n",
      "[397]\tvalid_0's l2: 0.0497671\n",
      "[398]\tvalid_0's l2: 0.0497669\n",
      "[399]\tvalid_0's l2: 0.0497665\n",
      "[400]\tvalid_0's l2: 0.0497664\n",
      "[401]\tvalid_0's l2: 0.0497663\n",
      "[402]\tvalid_0's l2: 0.0497662\n",
      "[403]\tvalid_0's l2: 0.0497658\n",
      "[404]\tvalid_0's l2: 0.0497658\n",
      "[405]\tvalid_0's l2: 0.049766\n",
      "[406]\tvalid_0's l2: 0.0497655\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's l2: 0.0497641\n"
     ]
    }
   ],
   "source": [
    "#p_ae = {'dim_1': 675, 'dim_2': 400, 'dim_3': 224, 'hidden': 162,\n",
    "#         'activation': nn.ReLU, 'dropout': 0.2916447561918717, 'lr': 0.030272591341587315,\n",
    "#         'recon_loss_factor': 0.4447516076774931, 'batch_size': 1252, 'loss_sup_ae': nn.MSELoss,\n",
    "#         'loss_recon': nn.MSELoss,\n",
    "#         'embedding': True,\n",
    "#         'input_size':310,'output_size':1}\n",
    "\n",
    "#p_res = {'dim_1': 843, 'dim_2': 2637, 'dim_3': 1618, 'dim_4': 880, 'dim_5': 220, 'activation': nn.LeakyReLU, 'dropout': 0.453246718032545, 'lr': 0.04565788979670108, 'batch_size': 10836,'loss':nn.MSELoss,'embedding':True,'input_size':310,'output_size':1,'hidden_len':p_ae['hidden']}\n",
    "#model_res = resnet.ResNet(input_size=p_res['input_size'],output_size=p_res['output_size'],params=p_res)\n",
    "#model_res.load_state_dict(torch.load('./saved_models/trained/ResNet_state_dict.pth'))\n",
    "#model_ae = utils.load_model(path='./saved_models/trained/trained_ae.pth',p=p_ae,pl_lightning=False,model=SupAE)\n",
    "p_lgbm = \t{'learning_rate': 0.010758658263835987, 'max_leaves': 80, 'bagging_fraction': 0.4927572426577223, 'bagging_freq': 10, 'feature_fraction': 0.4023243616563433, 'min_data_in_leaf': 686, 'lambda_l1': 0.04534825564399065, 'lambda_l2': 0.0409642610305239, 'boosting': 'gbdt', 'objective': 'regression',\n",
    "         'verbose':          1,\n",
    "         'n_jobs':           4,\n",
    "         'metric':           'mse'}\n",
    "data = utils.load_data('data/', mode='train')\n",
    "data, target, features, era = utils.preprocess_data(data, nn=True)\n",
    "data_dict = {'data':     data, 'target': target,\n",
    "                 'features': features, 'era': era}\n",
    "scores = []\n",
    "sizes = []\n",
    "models_lgbm = []\n",
    "# gts = GroupTimeSeriesSplit()\n",
    "gts = pgs.PurgedGroupTimeSeriesSplit(n_splits=5, group_gap=10)\n",
    "seed_everything(0)\n",
    "for i, (tr_idx, val_idx) in enumerate(gts.split(data_dict['data'], groups=data_dict['era'])):\n",
    "    sizes.append(len(tr_idx) + len(val_idx))\n",
    "    x_tr, x_val = data_dict['data'][tr_idx], data_dict['data'][val_idx]\n",
    "    y_tr, y_val = data_dict['target'][tr_idx], data_dict['target'][val_idx]\n",
    "    train = lgb.Dataset(x_tr, label=y_tr)\n",
    "    val = lgb.Dataset(x_val, label=y_val)\n",
    "    clf = lgb.train(p_lgbm, train, 500, valid_sets=[val], early_stopping_rounds=50, verbose_eval=True)\n",
    "    preds = clf.predict(x_val)\n",
    "    score = mean_squared_error(y_val, preds)\n",
    "    scores.append(score)\n",
    "    models_lgbm.append(clf)\n",
    "    del clf, preds, train, val, x_tr, x_val, y_tr, y_val, score\n",
    "    rubbish = gc.collect()\n",
    "#model_lgbm = clf\n",
    "models_dict = {'lgb':[models_lgbm, p_lgbm]}\n",
    "#models_dict = {'ResNet':[model_res,p_res],'ae':[model_ae,p_ae]}\n",
    "#models_dict = {'ae':[model_ae,p_ae]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import root\n",
    "from models.SupervisedAutoEncoder import create_hidden_rep\n",
    "from operator import mod\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "import dotenv\n",
    "import datatable as dt\n",
    "from dotenv.main import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from torch.utils.data import Dataset, Subset, BatchSampler, SequentialSampler, DataLoader\n",
    "\n",
    "root_dir = './data'\n",
    "test_files_path, test_files_exist = utils.check_test_files(root_dir)\n",
    "#df_out = pd.DataFrame()\n",
    "if test_files_exist:\n",
    "    test_files = os.listdir(test_files_path)\n",
    "for idx, file in enumerate(test_files):\n",
    "    df = utils.load_data(root_dir='./data', mode='test',\n",
    "                    overide=f'{test_files_path}/{file}')\n",
    "    df['target'] = 0\n",
    "    data, target, features, era = utils.preprocess_data(data=df, ordinal=True)\n",
    "    t_idx = np.arange(start=0, stop=len(era), step=1).tolist()\n",
    "    data_dict = data_dict = {'data': data, 'target': target,\n",
    "                                'features': features, 'era': era}\n",
    "    models_lgb=models_lgbm\n",
    "    x_val = data_dict['data']\n",
    "    preds = []\n",
    "    for model in models_lgb:\n",
    "        preds.append(model.predict(x_val))\n",
    "    predictions_lgb = np.mean(preds,axis=0)\n",
    "    df['prediction_lgb'] = predictions_lgb\n",
    "    df = df[['id', 'prediction_lgb']]\n",
    "    pred_path = f'{utils.get_data_path(root_dir)}/predictions/{era[0]}'\n",
    "    df.to_csv(f'{pred_path}.csv')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "#models_lgb = models['lgb'][0]\n",
    "#p_lgb = models['lgb'][1]\n",
    "models_lgb=models_lgbm\n",
    "x_val = data_dict['data']\n",
    "preds = []\n",
    "for model in models_lgb:\n",
    "    preds.append(model.predict(x_val))\n",
    "predictions_lgb = np.mean(preds,axis=0)\n",
    "#df['prediction_lgb'] = pd.DataFrame.from_dict({'era':era,'preds':predictions_lgb,'target':target.T})\n",
    "#df['prediction_lgb'] = \n",
    "#df = df[['id', 'prediction_lgb']]\n",
    "\n",
    "#utils.create_predictions(models=models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict({'era':era,'preds':predictions_lgb,'target':target.T})\n",
    "#df['prediction_lgb'] = pd.DataFrame.from_dict({'era':era,'preds':predictions_lgb,'target':target.T})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction_lgb'] =  predictions_lgb\n",
    "df = df[['id', 'prediction_lgb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_prediction_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = f\"{utils.get_data_path(root_dir='./data')}/predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_data(root_dir='./data/',mode='test')\n",
    "df['era'][df['era'] == 'eraX'] = 'era999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_eras = df['era'].unique().tolist()\n",
    "#val_eras[335]='era999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_eras = df[df['data_type']=='validation']['era'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eras = os.listdir(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [f\"era{era.replace('.csv','')}\" for era in val_eras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [era for era in eras if era in eras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eras =[era.replace('era','') for era in eras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [f'{era}.csv' for era in eras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'data_loading.utils' from 'c:\\\\Users\\\\e28898\\\\Documents\\\\GitHub\\\\Numerai\\\\data_loading\\\\utils.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = utils.create_prediction_file(eras=eras)\n",
    "df_example = dt.fread('.\\data\\numerai_dataset_261\\example_predictions.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = dt.fread('./data/numerai_dataset_261/example_predictions.csv').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back= df_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=df_preds.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e=df_example.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=df_p.reindex_like(df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_r=df_p.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[[\"prediction\"]].to_csv('pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-28 20:57:48,738 INFO numerapi.base_api: uploading predictions...\n",
      "2021-04-28 20:57:50,835 ERROR numerapi.base_api: invalid tournament\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "invalid tournament",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-019e30076cf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnumapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/e28898/Documents/GitHub/Numerai/data/numerai_dataset_261/predictions/predictions.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtournament\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current_round\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numerapi\\numerapi.py\u001b[0m in \u001b[0;36mupload_predictions\u001b[1;34m(self, file_path, tournament, model_id)\u001b[0m\n\u001b[0;32m    778\u001b[0m                      \u001b[1;34m'modelId'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m                      'triggerId': os.getenv('TRIGGER_ID', None)}\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mcreate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthorization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m         \u001b[0msubmission_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_submission'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msubmission_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numerapi\\base_api.py\u001b[0m in \u001b[0;36mraw_query\u001b[1;34m(self, query, variables, authorization)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_call_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# fail!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid tournament"
     ]
    }
   ],
   "source": [
    "numapi.upload_predictions(\"C:/Users/e28898/Documents/GitHub/Numerai/data/numerai_dataset_261/predictions/predictions.csv\", tournament=numapi.get_current_round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(predictions, targets):\n",
    "    ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "\n",
    "# convenience method for scoring\n",
    "def scoring(df):\n",
    "    return correlation(df['prediction'], df['target'])\n",
    "\n",
    "\n",
    "# Payout is just the score cliped at +/-25%\n",
    "def payout(scores):\n",
    "    return scores.clip(lower=-0.25, upper=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_preds, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.groupby('era').apply(scoring)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_data(root_dir='./data/',mode='test')\n",
    "df = df[df['data_type'] == 'validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_data(root_dir='./data/',mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['era'][df['era'] == 'eraX'] = 'era999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,target,features,era = utils.preprocess_data(df,ordinal=True)\n",
    "data_test,target_test,features_test,era_test = utils.preprocess_data(df_test,ordinal=True)\n",
    "\"\"\"\n",
    "data_ = copy.deepcopy(data)\n",
    "target_ = copy.deepcopy(target)\n",
    "oe = OrdinalEncoder()\n",
    "data = oe.fit_transform(data)\n",
    "target=oe.fit_transform(target_.values.reshape(-1,1)).reshape(-1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df ,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autoencodr training\n",
    "data = np.concatenate([data,data_test],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.concatenate([target,target_test],0)\n",
    "era = np.concatenate([era,era_test],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_idx = np.arange(start=0,stop=len(era),step=1).tolist()\n",
    "t_idx =np.where(era <121)[0].tolist()\n",
    "v_idx =np.where(era >=121)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = joblib.load('./hpo/params/SupAEnn_hpo_2021-04-05.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p['activation'] = nn.ReLU\n",
    "p['loss_sup_ae']= nn.MSELoss\n",
    "p['loss_recon']= nn.MSELoss\n",
    "p['embedding']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.FinData(data = data,target=target,era=era)\n",
    "dataloaders = utils.create_dataloaders(dataset,indexes={'train':t_idx,'val':v_idx},batch_size=p['batch_size'])\n",
    "p['input_size'] = len(features)\n",
    "p['output_size'] = 1\n",
    "model = SupAE(params=p)\n",
    "es = EarlyStopping(monitor='val_sup_loss',patience=10,min_delta=0.0005,mode='min')\n",
    "trainer = pl.Trainer(max_epochs=100,gpus=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = next(iter(dataloaders['val']))\n",
    "batch['era']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,train_dataloader = dataloaders['train'],val_dataloaders=dataloaders['val'])\n",
    "torch.save(model.state_dict(),f'./saved_models/trained/ae_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xgb = joblib.load('./hpo/params/xgb_hpo_2021-04-05.pkl').best_params\n",
    "p_lgb = joblib.load('./hpo/params/lgb_hpo_2021-04-05.pkl').best_params\n",
    "p_lgb['boosting']= 'gbdt'\n",
    "p_lgb['max_depth']= 50\n",
    "p_lgb['objective']= 'regression'\n",
    "p_lgb['metric']= 'mse'\n",
    "p_lgb['n_jobs']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data_dict = {'data': data, 'target': target,\n",
    "                                 'features': features, 'era': era}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val = data_dict['data'][t_idx], data_dict['data'][v_idx]\n",
    "y_tr, y_val = data_dict['target'][t_idx],data_dict['target'][v_idx]\n",
    "d_tr = lgb.Dataset(x_tr,label=y_tr)\n",
    "d_val = lgb.Dataset(x_val,label=y_val)\n",
    "clf = lgb.train(p_lgb,d_tr,1000,valid_sets=[d_val],early_stopping_rounds=50,verbose_eval=True)\n",
    "clf.save_model(f'./saved_models/trained/lgb.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'data': data, 'target': target,\n",
    "                 'features': features, 'era': era}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ae['input_size'] = len(features)\n",
    "p_ae['output_size'] = 1\n",
    "model = utils.load_model('./saved_models/trained/trained_ae.pth',\n",
    "                    p=p_ae, pl_lightning=False, model=SupAE)\n"
   ]
  },
  {
   "source": [
    "\n",
    "models_dict = {'lgb':[clf,p_lgb]}"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_output = create_hidden_rep(model, data_dict)\n",
    "data_dict['hidden'],ae_preds = ae_output['hidden'], ae_output['preds']\n",
    "data_dict['hidden_true'] = True\n",
    "p['hidden_len'] = data_dict['hidden'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.FinData(\n",
    "            data=data_dict['data'], target=data_dict['target'], era=data_dict['era'], hidden=data_dict.get('hidden', None))\n",
    "dataloaders = utils.create_dataloaders(\n",
    "            dataset, indexes={'train': t_idx}, batch_size=p['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res = {'dim_1': 843, 'dim_2': 2637, 'dim_3': 1618, 'dim_4': 880, 'dim_5': 220, 'activation': nn.LeakyReLU, 'dropout': 0.453246718032545, 'lr': 0.04565788979670108, 'batch_size': 10836,'loss':nn.MSELoss,'embedding':True,'input_size':310,'output_size':1,'hidden_len':p_ae['hidden']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.ResNet(input_size = p['input_size'],output_size=p['output_size'],params=p)\n",
    "es = EarlyStopping(monitor='val_mse',patience=10,min_delta=0.0005,mode='min')\n",
    "trainer = pl.Trainer(max_epochs=100,gpus=1,callbacks=[es])\n",
    "trainer.fit(model,train_dataloader=dataloaders['train'],val_dataloaders=dataloaders['val'])\n",
    "torch.save(model.state_dict(),f'./saved_models/trained/ResNet_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = utils.load_model('./saved_models/trained/ResNet_state_dict.pth',\n",
    " #                   p=p, pl_lightning=False, model=resnet.ResNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = resnet.ResNet(input_size=p_res['input_size'],output_size=p_res['output_size'],params=p_res)\n",
    "model_res.load_state_dict(torch.load('./saved_models/trained/ResNet_state_dict.pth'))\n",
    "model_ae = utils.load_model(path='./saved_models/trained/trained_ae.pth',p=p_ae,pl_lightning=False,model=SupAE)\n",
    "models_dict = {'ResNet':[model_res,p_res],'ae':[model_ae,p_ae]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_predictions(models=models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p['input_size'] = len(features)\n",
    "p['output_size'] = 1\n",
    "train = True\n",
    "if train:\n",
    "    gts = purged_group_time_series.PurgedGroupTimeSeriesSplit(n_splits=5,group_gap=5)\n",
    "    models=[]\n",
    "    for i, (train_idx,val_idx) in enumerate(gts.split(data,groups=era)):\n",
    "        dataset = utils.FinData(data=data, target=target, era=era)\n",
    "        dataloaders = utils.create_dataloaders(\n",
    "        dataset, indexes={'train': train_idx, 'val': val_idx}, batch_size=p['batch_size'])\n",
    "        model = SupAE(p)\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10,\n",
    "                            min_delta=0.005, mode='min')\n",
    "        trainer = pl.Trainer(max_epochs=100,\n",
    "                                gpus=1,\n",
    "                                callbacks=[es])\n",
    "        trainer.fit(\n",
    "            model, train_dataloader=dataloaders['train'], val_dataloaders=dataloaders['val'])\n",
    "        torch.save(model.state_dict(), f'saved_models/ae_fold_{i}_state_dict.pth')\n",
    "        models.append(model)\n",
    "else:\n",
    "    models_nn = utils.load_model('./saved_models/AE',p=p,pl_lightning=False,model=SupAE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_,_,_,_ = utils.preprocess_data(df,nn=True)\n",
    "\n",
    "p = {'learning_rate': 0.030803514080008098,\n",
    "         'max_leaves': 50,\n",
    "         'bagging_fraction': 0.9011886437667906,\n",
    "         'bagging_freq': 5,\n",
    "         'feature_fraction': 0.3287921216266973,\n",
    "         'min_data_in_leaf': 396,\n",
    "         'lambda_l1': 0.02217696438630042,\n",
    "         'lambda_l2': 0.03985756503899372,\n",
    "         'boosting': 'gbdt',\n",
    "         'max_depth': 50,\n",
    "         'objective': 'regression',\n",
    "         'metric': 'mse',\n",
    "         'n_jobs':-1}\n",
    "gts = purged_group_time_series.PurgedGroupTimeSeriesSplit(n_splits=5,group_gap=5)\n",
    "models_gbm = []\n",
    "scores = []\n",
    "for i, (tr_idx,val_idx) in enumerate(gts.split(data_,groups=era)):\n",
    "    x_tr, x_val = data_[tr_idx], data_[val_idx]\n",
    "    y_tr, y_val = target[tr_idx],target[val_idx]\n",
    "    d_tr = lgb.Dataset(x_tr,label=y_tr)\n",
    "    d_val = lgb.Dataset(x_val,label=y_val)\n",
    "    clf = lgb.train(p,d_tr,1000,valid_sets=[d_val],early_stopping_rounds=50,verbose_eval=True)\n",
    "    preds = clf.predict(x_val)\n",
    "    score = mean_squared_error(y_val,preds)\n",
    "    print(f'Fold {i} MSE score:\\t', score)\n",
    "    models_gbm.append(clf)\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_,df,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = data\n",
    "output_size= 1\n",
    "p = {'dim_1': 1500,\n",
    "    'dim_2': 1000,\n",
    "    'dim_3': 500,\n",
    "    'dim_4': 250,\n",
    "    'dim_5': 150,\n",
    "    'activation': nn.SiLU,\n",
    "    'dropout': 0.2,\n",
    "    'lr': 0.05,\n",
    "    'label_smoothing':0.1,\n",
    "    'amsgrad': False,\n",
    "    'batch_size': 5000,\n",
    "    'loss':nn.MSELoss(),\n",
    "    'embedding':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.FinData(data=data, target=target, era=era)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_nn[-1]\n",
    "model.eval().to('cuda')\n",
    "index = np.linspace(0,dataset.data.shape[0],dataset.data.shape[0],dtype='int')"
   ]
  },
  {
   "source": [
    "batch_size = 5000\n",
    "dataloaders = utils.create_dataloaders(dataset,{'train':index.tolist()},batch_size=batch_size)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens =[]\n",
    "for i, batch in enumerate(dataloaders['train']):\n",
    "    _,hidden,_,_ = model(batch['data'].view(batch['data'].size(1),-1).to('cuda'))\n",
    "    hiddens.append(hidden.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = np.array([hiddens[i][j] for i in range(len(hiddens)) for j in range(len(hiddens[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.concatenate([data,hiddens],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gts = purged_group_time_series.PurgedGroupTimeSeriesSplit(n_splits=5,group_gap=5)\n",
    "dataset = utils.FinData(data=data, target=target, era=era)\n",
    "models=[]\n",
    "for i, (train_idx,val_idx) in enumerate(gts.split(data,groups=era)):\n",
    "    \n",
    "    dataloaders = utils.create_dataloaders(\n",
    "    dataset, indexes={'train': train_idx, 'val': val_idx}, batch_size=p['batch_size'])\n",
    "    model = resnet.ResNet(input_size=input_size,output_size=output_size,params=p)\n",
    "    #model.apply(lambda x: utils.init_weights(x,'relu'))\n",
    "    es = EarlyStopping(monitor='val_mse', patience=10,\n",
    "                        min_delta=0.005, mode='min')\n",
    "    trainer = pl.Trainer(max_epochs=100,\n",
    "                            gpus=1,\n",
    "                            callbacks=[es])\n",
    "    trainer.fit(\n",
    "        model, train_dataloader=dataloaders['train'], val_dataloaders=dataloaders['val'])\n",
    "    torch.save(model.state_dict(), f'saved_models/Resnet/fold_{i}_state_dict.pth')\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = utils.load_data(root_dir='./data/',mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data,target,features,era = utils.preprocess_data(df.iloc[:10000,],test=True,ordinal=True)\n",
    "data_,_,_,_=utils.preprocess_data(df.iloc[:10000,],test=True,nn=True)\n",
    "\"\"\"\n",
    "data = data[0:1000]\n",
    "oe = OrdinalEncoder()\n",
    "data = oe.fit_transform(data)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = torch.tensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(predictions, targets):\n",
    "    ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "\n",
    "# convenience method for scoring\n",
    "def scoring(df):\n",
    "    return correlation(df['preds'], df['target'])\n",
    "\n",
    "\n",
    "# Payout is just the score cliped at +/-25%\n",
    "def payout(scores):\n",
    "    return scores.clip(lower=-0.25, upper=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models_nn:\n",
    "    model.eval()\n",
    "    preds.append(model(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [preds[i][1].detach().numpy() for i in range(len(preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = np.mean(predictions,axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame.from_dict({'era':era,'preds':predictions,'target':target.T})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corrs = df_preds.groupby('era').apply(scoring)\n",
    "corrs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "payout(corrs).mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = models_nn[0](data).reshape(-1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models_gbm:\n",
    "    preds.append(model.predict(data_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_gbm = np.mean(preds,axis=0)\n",
    "df_gbm = pd.DataFrame.from_dict({'era':era,'preds':predictions_gbm,'target':target.T})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_gbm = df_gbm.groupby('era').apply(scoring)\n",
    "corrs_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payout(corrs_gbm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['data_type']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wojhed-riDni0-hopnok"
   ]
  }
 ]
}