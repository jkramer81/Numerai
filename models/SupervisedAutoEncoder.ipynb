{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import joblib\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from data_loading import utils\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "\n",
        "class SupAE(pl.LightningModule):\n",
        "    def __init__(self, params):\n",
        "        super(SupAE, self).__init__()\n",
        "        self.lr = params['lr']\n",
        "        self.loss_recon = params['loss_recon']()\n",
        "        self.recon_loss_factor = params['recon_loss_factor']\n",
        "        self.loss_sup_ae = params['loss_sup_ae']()\n",
        "        self.activation = params['activation']\n",
        "        self.drop = params['dropout']\n",
        "        cat_dims = [5 for i in range(params['input_size'])]\n",
        "        emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\n",
        "        self.embedding_layers = nn.ModuleList(\n",
        "            [nn.Embedding(x, y) for x, y in emb_dims]).to(self.device)\n",
        "        self.num_embeddings = sum([y for x, y in emb_dims])\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.num_embeddings, params['dim_1']),\n",
        "            nn.BatchNorm1d(params['dim_1']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_1'], params['dim_2']),\n",
        "            nn.BatchNorm1d(params['dim_2']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_2'], params['dim_3']),\n",
        "            nn.BatchNorm1d(params['dim_3']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_3'], params['hidden'])\n",
        "        )\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.BatchNorm1d(params['hidden']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['hidden'], params['output_size'])\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(params['hidden'], params['dim_3']),\n",
        "            nn.BatchNorm1d(params['dim_3']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_3'], params['dim_2']),\n",
        "            nn.BatchNorm1d(params['dim_2']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_2'], params['dim_1']),\n",
        "            nn.BatchNorm1d(params['dim_1']),\n",
        "            self.activation(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(params['dim_1'], self.num_embeddings)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = [emb_lay(x[:, i])\n",
        "             for i, emb_lay in enumerate(self.embedding_layers)]\n",
        "        emb = torch.cat(x, 1)\n",
        "        hidden = self.encoder(emb)\n",
        "        reg_out = self.regressor(hidden)\n",
        "        decoder_out = self.decoder(hidden)\n",
        "        return emb, hidden, reg_out, decoder_out\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch['data'], batch['target']\n",
        "        x = x.view(x.size(1), -1)\n",
        "        y = y.T\n",
        "        emb, _, reg_out, decoder_out = self(x)\n",
        "        sup_loss = self.loss_sup_ae(reg_out, y)\n",
        "        recon_loss = torch.mean(torch.tensor(\n",
        "            [self.loss_recon(decoder_out[i], emb[i]) for i in range(x.shape[0])]))\n",
        "        loss = sup_loss + self.recon_loss_factor*recon_loss\n",
        "        self.log('sup_loss', sup_loss, on_step=False,\n",
        "                 on_epoch=True, prog_bar=True)\n",
        "        self.log('recon_loss', recon_loss, on_step=False,\n",
        "                 on_epoch=True, prog_bar=True)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch['data'], batch['target']\n",
        "        x = x.view(x.size(1), -1)\n",
        "        y = y.T\n",
        "        emb, _, reg_out, decoder_out = self(x)\n",
        "        sup_loss = self.loss_sup_ae(reg_out, y)\n",
        "        recon_loss = torch.mean(torch.tensor(\n",
        "            [self.loss_recon(decoder_out[i], emb[i]) for i in range(x.shape[0])]))\n",
        "        loss = sup_loss + self.recon_loss_factor*recon_loss\n",
        "        \"\"\"\n",
        "        self.log('sup_loss', sup_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('recon_loss', recon_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        \"\"\"\n",
        "        return {'val_loss': loss, 'val_sup_loss': sup_loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs) -> None:\n",
        "        epoch_loss = torch.tensor([x['val_loss'] for x in outputs]).mean()\n",
        "        epoch_sup_loss = torch.tensor(\n",
        "            [x['val_sup_loss'] for x in outputs]).mean()\n",
        "        self.log('val_loss', epoch_loss, prog_bar=True)\n",
        "        self.log('val_sup_loss', epoch_sup_loss, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, patience=5, factor=0.1, min_lr=1e-7, eps=1e-08\n",
        "        )\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n",
        "\n",
        "\n",
        "def train_ae_model(data_dict):\n",
        "    # TODO Dynamic\n",
        "    p = {'dim_1': 675, 'dim_2': 400, 'dim_3': 224, 'hidden': 162,\n",
        "         'activation': nn.ReLU, 'dropout': 0.2916447561918717, 'lr': 0.030272591341587315,\n",
        "         'recon_loss_factor': 0.4447516076774931, 'batch_size': 1252, 'loss_sup_ae': nn.MSELoss,\n",
        "         'loss_recon': nn.MSELoss,\n",
        "         'embedding': True}\n",
        "    # TODO Fix this\n",
        "    joblib.dump(p,'./saved_models/parameters/ae_params.pkl')\n",
        "    train_idx = np.arange(start=0, stop=452205, step=1, dtype=np.int).tolist()\n",
        "    val_idx = np.arange(start=452206, stop=len(\n",
        "        data_dict['data']), step=1, dtype=np.int).tolist()\n",
        "    p['input_size'] = len(data_dict['features'])\n",
        "    p['output_size'] = 1\n",
        "    dataset = utils.FinData(\n",
        "        data=data_dict['data'], target=data_dict['target'], era=data_dict['era'])\n",
        "    dataloaders = utils.create_dataloaders(dataset=dataset, indexes={\n",
        "                                           'train': train_idx, 'val': val_idx}, batch_size=p['batch_size'])\n",
        "    model = SupAE(p)\n",
        "    es = EarlyStopping(monitor='val_loss', patience=10,\n",
        "                       min_delta=0.005, mode='min')\n",
        "    trainer = pl.Trainer(max_epochs=100,\n",
        "                         gpus=0,\n",
        "                         callbacks=[es])\n",
        "    trainer.fit(\n",
        "        model, train_dataloader=dataloaders['train'], val_dataloaders=dataloaders['val'])\n",
        "    torch.save(model.state_dict(), f'./saved_models/trained/trained_ae.pth')\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_hidden_rep(model, data_dict):\n",
        "    model.eval()\n",
        "    index = np.linspace(\n",
        "        0, data_dict['data'].shape[0]-1, data_dict['data'].shape[0], dtype='int').tolist()\n",
        "    dataset = utils.FinData(\n",
        "        data_dict['data'], target=data_dict['target'], era=data_dict['era'])\n",
        "    batch_size = 5000\n",
        "    dataloaders = utils.create_dataloaders(\n",
        "        dataset, {'train': index}, batch_size=batch_size)\n",
        "    hiddens = []\n",
        "    predictions = []\n",
        "    for i, batch in enumerate(dataloaders['train']):\n",
        "        _, hidden, pred, _ = model(batch['data'].view(\n",
        "            batch['data'].size(1), -1))\n",
        "        hiddens.append(hidden.cpu().detach().numpy().tolist())\n",
        "        predictions.append(pred.cpu().detach().numpy().tolist())\n",
        "    hiddens = np.array([hiddens[i][j] for i in range(\n",
        "        len(hiddens)) for j in range(len(hiddens[i]))])\n",
        "    preds = np.array([predictions[i][j] for i in range(\n",
        "        len(predictions)) for j in range(len(predictions[i]))])\n",
        "    return {'hidden': hiddens, 'preds': preds}"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}