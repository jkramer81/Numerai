{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
        "from sklearn.utils.validation import _deprecate_positional_args\n",
        "import numpy as np\n",
        "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
        "\n",
        "\n",
        "class GroupTimeSeriesSplit(_BaseKFold):\n",
        "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
        "    Provides train/test indices to split time series data samples\n",
        "    that are observed at fixed time intervals according to a\n",
        "    third-party provided group.\n",
        "    In each split, test indices must be higher than before, and thus shuffling\n",
        "    in cross validator is inappropriate.\n",
        "    This cross-validation object is a variation of :class:`KFold`.\n",
        "    In the kth split, it returns first k folds as train set and the\n",
        "    (k+1)th fold as test set.\n",
        "    The same group will not appear in two different folds (the number of\n",
        "    distinct groups has to be at least equal to the number of folds).\n",
        "    Note that unlike standard cross-validation methods, successive\n",
        "    training sets are supersets of those that come before them.\n",
        "    Read more in the :ref:`User Guide <cross_validation>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_splits : int, default=5\n",
        "        Number of splits. Must be at least 2.\n",
        "    max_train_size : int, default=None\n",
        "        Maximum size for a single training set.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import numpy as np\n",
        "    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n",
        "    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n",
        "                           'b', 'b', 'b', 'b', 'b',\\\n",
        "                           'c', 'c', 'c', 'c',\\\n",
        "                           'd', 'd', 'd'])\n",
        "    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n",
        "    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n",
        "    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
        "    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n",
        "                  \"TEST GROUP:\", groups[test_idx])\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n",
        "    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n",
        "    TEST GROUP: ['c' 'c' 'c' 'c']\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n",
        "    TEST: [15, 16, 17]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n",
        "    TEST GROUP: ['d' 'd' 'd']\n",
        "    \"\"\"\n",
        "    @_deprecate_positional_args\n",
        "    def __init__(self,\n",
        "                 n_splits=5,\n",
        "                 *,\n",
        "                 max_train_size=None\n",
        "                 ):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.max_train_size = max_train_size\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        \"\"\"Generate indices to split data into training and test set.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Always ignored, exists for compatibility.\n",
        "        groups : array-like of shape (n_samples,)\n",
        "            Group labels for the samples used while splitting the dataset into\n",
        "            train/test set.\n",
        "        Yields\n",
        "        ------\n",
        "        train : ndarray\n",
        "            The training set indices for that split.\n",
        "        test : ndarray\n",
        "            The testing set indices for that split.\n",
        "        \"\"\"\n",
        "        if groups is None:\n",
        "            raise ValueError(\n",
        "                \"The 'groups' parameter should not be None\")\n",
        "        X, y, groups = indexable(X, y, groups)\n",
        "        n_samples = _num_samples(X)\n",
        "        n_splits = self.n_splits\n",
        "        n_folds = n_splits + 1\n",
        "        group_dict = {}\n",
        "        u, ind = np.unique(groups, return_index=True)\n",
        "        unique_groups = u[np.argsort(ind)]\n",
        "        n_samples = _num_samples(X)\n",
        "        n_groups = _num_samples(unique_groups)\n",
        "        for idx in np.arange(n_samples):\n",
        "            if (groups[idx] in group_dict):\n",
        "                group_dict[groups[idx]].append(idx)\n",
        "            else:\n",
        "                group_dict[groups[idx]] = [idx]\n",
        "        if n_folds > n_groups:\n",
        "            raise ValueError(\n",
        "                (\"Cannot have number of folds={0} greater than\"\n",
        "                 \" the number of groups={1}\").format(n_folds,\n",
        "                                                     n_groups))\n",
        "        group_test_size = n_groups // n_folds\n",
        "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
        "                                  n_groups, group_test_size)\n",
        "        for group_test_start in group_test_starts:\n",
        "            train_array = []\n",
        "            test_array = []\n",
        "            for train_group_idx in unique_groups[:group_test_start]:\n",
        "                train_array_tmp = group_dict[train_group_idx]\n",
        "                train_array = np.sort(np.unique(\n",
        "                                      np.concatenate((train_array,\n",
        "                                                      train_array_tmp)),\n",
        "                                      axis=None), axis=None)\n",
        "            train_end = train_array.size\n",
        "            if self.max_train_size and self.max_train_size < train_end:\n",
        "                train_array = train_array[train_end -\n",
        "                                          self.max_train_size:train_end]\n",
        "            for test_group_idx in unique_groups[group_test_start:\n",
        "                                                group_test_start +\n",
        "                                                group_test_size]:\n",
        "                test_array_tmp = group_dict[test_group_idx]\n",
        "                test_array = np.sort(np.unique(\n",
        "                    np.concatenate((test_array,\n",
        "                                    test_array_tmp)),\n",
        "                    axis=None), axis=None)\n",
        "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}